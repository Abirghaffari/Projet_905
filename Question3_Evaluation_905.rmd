---
title: "Evaluation_905_Question3"
author: "Abir Ben Abdelghaffar/Alban LAMGHARI/Mohamed DUMONT"
date: "12/07/2024"
output: 
      html_document:
    toc: true
---
```{r}
# Installation des Bibliothèques nécessaires 
install.packages("l4m")
install.packages("car")
install.packages("ggplot2")
# Chargement de dataframe 
data <- read.csv("G:/Mon Drive/Evaluation_905/dataProjet_2025.csv")
head(data)
```

```{r}
# Filtrage des lignes où 'recherche-esp_Ib_nom_plantae' est "Carpinus betulus L., 1753"
data_Chêne <- data[data$recherche_esp_lb_nom_plantae == "Quercus L., 1753",]

head(data_Chêne)
summary(data_Chêne)
```
# Proposition d'une Visualisation Graphique de triangulation des rélevés

```{r}
plot(lati~long, data=data_Chêne,xlab="Longitude WGS84",ylab="Latitude WGS84",pch=3)
coorPla <- sapply(unique(dataIni$releve),function(idPla){
 vIndPla <- which(dataIni$releve==idPla)
 latiPla <- mean(dataIni$lati[vIndPla],na.rm=TRUE)
 longPla <- mean(dataIni$long[vIndPla],na.rm=TRUE)
 return(c(longPla,latiPla))
})
text(coorPla[1,],coorPla[2,],colnames(coorPla),col=4,cex=0.5,font=2)
```
#Modèle Anova : DBH *Sous-population

```{r}
# Étape 1 : Supprimer les lignes avec des valeurs NA (si ce n'est pas déjà fait)
data_Chêne_clean <- data_Chêne[complete.cases(data_Chêne[, c("long", "lati")]), ]

# Étape 2 : Calculer la matrice de distance et effectuer le clustering hiérarchique
dist_matrix <- dist(data_Chêne_clean[, c("long", "lati")])
hclust_result <- hclust(dist_matrix, method = "ward.D")

# Étape 3 : Découper en clusters (par exemple, 3 clusters)
clusters <- cutree(hclust_result, k = 3)

# Étape 4 : Ajouter les clusters aux données filtrées
data_Chêne_clean$cluster <- clusters

# Étape 5 : Ajouter les clusters au jeu de données original
data_Chêne$cluster <- NA  # Initialiser une colonne avec NA
data_Chêne$cluster[complete.cases(data_Chêne[, c("long", "lati")])] <- clusters
head(data_Chêne)
nrow(data_Chêne)
```


```{r}
# Application d'un modèle ANOVA pour évaluer l'effet des sous-populations sur la variable d'étude (DBH)
modAnova <- lm(data_Chêne$DBH ~ 0 + cluster, data = data_Chêne)
```

# Vérification d'adéquation des Hypothèses de la loi Gaussienne 
# Hypothèse 1 : La normalité des erreurs (évaluation de la symétrie)
```{r}
library(car)
par(mfrow=c(1,2))
nul <- qqPlot(modAnova$residuals,distribution="norm",line="none")
hist(rstandard(modAnova))
```
En analysant les graphiques :

Graphique Q-Q (à gauche) :
  Les points suivent la ligne bleue au centre, mais s'écartent significativement aux extrémités (queues de la distribution). Cela   indique que les résidus présentent des déviations par rapport à la normalité, notamment dans les queues (kurtosis).
Histogramme (à droite) :
  L'histogramme montre une distribution légèrement asymétrique (légèrement biaisée). La forme n'est pas parfaitement symétrique    ni parfaitement en cloche.
Conclusion : Les résidus ne semblent pas parfaitement symétriques, ce qui suggère une légère déviation de la normalité. Donc une transformation de la variable dépendante peut être une solution pour améliorer la distribution des données.
# Vérification de la symétrie de distribution de données après une transformation logarithmique 

# 1. Vérification des valeurs abérrantes 

```{r}
# Identifier les valeurs aberrantes
standardized_residuals <- rstandard(modAnova)
data_Chêne[abs(standardized_residuals) > 3, ]  # Seuil commun pour détecter les outliers
# Créez un nouveau jeu de données sans les valeurs aberrantes
data_no_outliers <- data_Chêne[abs(standardized_residuals) <= 3, ]
# Vérifiez le nombre de lignes restantes
nrow(data_no_outliers)
```
Suite au script ci-dessus, nous avons trouvés 29 échantillons sur 1467 qui sont considérés comme abérants et dons nous avons décider de l'enlever de notre jeu de données et de faire tourner de nouveau notre modèle ANOVA avec la nouvelle jeu de donnée filtrée en appliquant une transformation logarithmique sur la variable dépendante " DBH".

`````{r}
data_no_outliers$DBH_log <- log(data_no_outliers$DBH)
modAnova_log <- lm(DBH_log ~ 0 + cluster, data = data_no_outliers)
library(car)
par(mfrow=c(1,2))
nul <- qqPlot(modAnova$residuals,distribution="norm",line="none")
hist(rstandard(modAnova))
```

L'élimination des valeurs abérantes et après l'application d'une transformation logarithmique ne résoudrent pas le problème d'une distribution non symétrique des données donc on peut tester une dexième transformation type Box-Cox en espérant qu'elle peut résoudre ce problème d'asymétrie.


# Transformation Box-Cox et Vérification de nouveau la validité de la première hypothèse de la loi Gaussiènne 
```{r}
modAnova_log <- lm(DBH ~ 0 + cluster, data = data_no_outliers)
modAnova_pT <- powerTransform(modAnova)
modAnova_pT$lambda
modAnova <- lm(data_no_outliers$DBH**modAnova_pT$lambda~0+cluster,data=data_no_outliers)
```
```{r}
library(car)
par(mfrow=c(1,2))
nul <- qqPlot(modAnova$residuals,distribution="norm",line="none")
hist(rstandard(modAnova))
```
D'après le resultats obtenu, même la transformation Box-Cox ne peut pas ajuster la distribution de données selon une distribution Gaussienne normale.
Donc , la solution proposé est de tester un modèle emboités pour voir si on peut vraiment fusionner les sous-populations dans un même cluster. 


# Modèle Emboités 
```{r}
modAnovReg<- lm(DBH~cluster+releve,data=data_Chêne) 
```

# Comparaison de deux modèles 
```{r}
modAnova <- lm(data_Chêne$DBH ~ 0 + cluster, data = data_Chêne)
modAnovReg<- lm(data_Chêne$DBH~cluster+releve,data=data_Chêne) 
anova(modAnova,modAnovReg)
```
# Hypothèses testées :
On test si l'ajout du facteur "relevé" améliore significativement la capacité explicative du modèle intial  (L'ANOVA appliqué sur les sous populations et pas sur le relvé d'une manière individuelle).

H0 (hypothèse nulle) : Le facteur "relevé" n'apporte pas d'information supplémentaire pour expliquer la variabilité de DBH.
H1 (hypothèse alternative) : Le facteur "relevé" apporte une information supplémentaire significative.

# Conclusion :
La p-valeur est très inférieure à 0.05 (< 2.2e-16 ), donc on rejette l'Hypothèse nulle.
Cela indique que le facteur "releve" apporte une contribution significative pour expliquer la variabilité de DBH au sein des clusters.
En d'autres termes, les relevés individuels à l'intérieur des triangles (clusters) représentent une source importante de variation dans les données. Donc pour expliquer la variabilité de diamètre des arbres, il vaut mieux établir un modèle ANOVA oû le variable explicative est le relévé  considéré d'une manière individuelle et pas rassemblés en triplet (cluster).
