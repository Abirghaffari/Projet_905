---
title: "Evaluation_905"
author: "Abir Ben Abdelghaffar/Alban LAMGHARI/Mohamed DUMONT"
date: "12/07/2024"
output: 
      html_document:
    toc: true
---

``````{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Installation des Biblioth√®ques n√©cessaires 
install.packages("l4m")
install.packages("car")
install.packages("ggplot")
# Chargement de dataframe 
data <- read.csv("G:/Mon Drive/Evaluation_905/dataProjet_2025.csv")
head(data)
```


```{r}

# Filtrage des lignes o√π 'recherche-esp_Ib_nom_plantae' est "Carpinus betulus L., 1753"

data_filtred <- data[data$recherche_esp_lb_nom_plantae == "Carpinus betulus L., 1753",]

head(data_filtred)
summary(data_filtred)

```


```{r}
# Visualisation graphique de l'ensemble des quantiles de l‚Äô√©chantillon 

fRep_DBH <- ecdf(data_filtred$DBH) 
plot(fRep_DBH,xlab="DBH",ylab="Quantile",main="Fonction de r√©partition de DBH")
```
```{r}
# Application d'un mod√®le ANOVA pour √©valuer l'effet de r√©lev√©e sur la variable d'√©tude diam√®tre des arbres de la classe Charme
modAnova <- lm(DBH~0+releve,data=data_filtred)
```

### Ad√©quation des erreurs (des r√©sidus) √† la loi gaussienne
on commence par v√©rifier que les hypoth√®ses sur les r√©sidus sont en ad√©quation avec les donn√©es utilis√©es : 

### Hypoth√®se 1 : loi gaussienne des erreurs (√©valuation de la sym√©trie) 
```{r}
library(car)
par(mfrow=c(1,2))
nul <- qqPlot(modAnova$residuals,distribution="norm",line="none")
hist(rstandard(modAnova))

```

L'asym√©trie observ√©e dans le graphique des r√©sidus (QQ-plot et histogramme) sugg√®re que les r√©sidus ne suivent pas une distribution normale(Gaussienne). Donc, une transformation de variable d√©pendante (DBH) peut aider √† corriger ce probl√®me.

# Transforamtion Box_Cox
 Comme les donn√©es sont fortement asym√©triques vers la droite (positivement asym√©trique ), on propose d'appliquer une transformation Box-Cox de type puissance.
 
```{r}
modAnova_pT <- powerTransform(modAnova)
modAnova_pT$lambda
modAnova <- lm(DBH**modAnova_pT$lambda~0+releve,data=data_filtred)
```

On v√©rifier de nouveau l'ad√©quation des r√©sidus √† la loi Gaussienne (v√©rification de la validt√© des diff√©rents hypoth√®se normalit√©(loi Gaussienne),l'ind√©pendance et l'homosc√©dasticit√©).

### Hypoth√®se 1 : loi gaussienne des erreurs (√©valuation de la sym√©trie)

```{r,fig.height=4,fig.width=8}
library(car)
par(mfrow=c(1,2))
nul <- qqPlot(modAnova$residuals,distribution="norm",line="none")
hist(rstandard(modAnova))
```
A partir de deux graphiques ci-dessus, on constate : 
***Un alignement  sur la Diagonale : Les points suivent globalement la ligne diagonale, ce qui sugg√®re que les r√©sidus suivent approximativement une distribution normale.

***D√©viations aux Extr√©mit√©s : Quelques points d√©vient de la ligne diagonale aux extr√©mit√©s, ce qui peut indiquer la pr√©sence de valeurs extr√™mes ou d'anomalies.

Par rapport √† l'histogramme des R√©sidus , on observe : 

***Une Distribution Centr√©e : La distribution des r√©sidus est centr√©e autour de z√©ro, ce qui est souhaitable.

Cependant,on note une l√©g√®re asym√©trie vers la gauche, ce qui sugg√®re que les r√©sidus ne sont pas parfaitement normalement distribu√©s.

***Forme de la Distribution : La forme g√©n√©rale de l'histogramme semble approximativement normale, mais la l√©g√®re asym√©trie et la pr√©sence de valeurs extr√™mes observ√©es dans le QQ plot doivent √™tre prises en compte.

Conclusion : 
***Normalit√© des R√©sidus : Les r√©sidus semblent suivre une distribution normale de mani√®re g√©n√©rale, avec quelques d√©viations mineures aux extr√©mit√©s. Cela sugg√®re que les hypoth√®ses de normalit√© des r√©sidus sont globalement respect√©es, mais il pourrait y avoir des valeurs extr√™mes √† examiner plus en d√©tail.

***Validation du Mod√®le : L'analyse visuelle des QQ plots et de l'histogramme permet de valider que le mod√®le ANOVA en appliquant une transformation Box-Cox sur la variable d√©pendante (DBH) est appropri√©, bien que certaines valeurs extr√™mes pourraient n√©cessiter une attention suppl√©mentaire.

### Hypoth√®se 2 : homosc√©dasticit√© des erreurs
Afin d'√©valuer l'homosc√©dasticit√© des erreurs, on peut utiliser un 
diagramme de localisation d'√©chelle (**scale-location plot** ou **SL-plot**).

```{r,fig.height=5,fig.width=5}
#SL-plot
plot(modAnova,which=3,pch=3, add.smooth = FALSE) #Base du SL-plot pr√©-programm√©e dans R
abline(h=0.8,col=4,lwd=2) #Ligne horizontale attendue
lo <- loess(sqrt(abs(rstandard(modAnova)))~modAnova$fitted.values) #Moyenne glissante des points
vFit <- sort(unique(modAnova$fitted.values))
predLo <- predict(lo,vFit,se=TRUE)
lines(predLo$fit~vFit,col=2,lwd=2)
#Enveloppe de confiance autour de cette moyenne glissante :
nFit <- length(vFit); ICBonf <- qnorm(1-0.05/2/nFit)
lines(predLo$fit+ICBonf*predLo$se.fit~sort(
    unique(modAnova$fitted.values)
  ),col=2,lwd=2,lty="dashed")
lines(predLo$fit-ICBonf*predLo$se.fit~sort(
    unique(modAnova$fitted.values)
  ),col=2,lwd=2,lty="dashed")
```

D'apr√®s le scale-location plot obtenu ci-dessus : 

***Les r√©sidus semblent √™tre r√©partis de mani√®re relativement homog√®ne autour de la ligne bleue, bien que quelques points extr√™mes soient pr√©sents.

***Les lignes de tendance rouge et bleue ne montrent pas de tendance marqu√©e √† augmenter ou √† diminuer syst√©matiquement avec les valeurs ajust√©es, sugg√©rant une variance constante des r√©sidus.

Ainsi, l'hypoth√®se d'homoc√©dasticit√© (homog√©nit√© des variances) est raisonnablement valide pour ce mod√®le, bien qu'on observe quelques points extr√™mes (d'anomalie).

### Hypoth√®se 03 : Ind√©pendance des erreurs 
Apr√®s avoir filtr√© pour ne conserver que les √©chantillons  relatif √† l'esp√®ce Charme et int√©gr√© l'effet du relev√© dans le mod√®le, il ne reste plus de variable susceptible de cr√©er une d√©pendance dans les r√©sidus, except√© peut-√™tre la position pr√©cise des arbres au sein des relev√©s ou peut-√™tre d'autres variabe en lien avec la qualit√© du sol ou la pr√©sence de l'eau mais on dispose pas ces informations dans le jeu de donn√©es √©tudi√©.
 Mais √ßa n'emp√™che pa d'appliquer un Test comme le Testde Durbin-Watsonest utilis√© pour d√©tecter la pr√©sence d'autocorr√©lation des r√©sidus.

```{r}
library(car) 
durbinWatsonTest(modAnova)

```
Les r√©sultats sugg√®rent une autocorr√©lation positive des r√©sidus (D-W Statistic < 2 ). L'hypoth√®se d'ind√©pendance des erreurs est donc viol√©e. Cela signifie que les erreurs ne sont pas ind√©pendantes les unes des autres, ce qui peut affecter la validit√© du mod√®le. Donc, on doit envisager un ajustement pour traiter cette autocorr√©lation, comme l'ajout de variables explicatives suppl√©mentaires(par exemple l'altitude).


On suppose que notre mod√®le est bien valid√©, autrement dit le relev√© a un effet significatif sur la variable d√©pendante (DBH) et les r√©sidus sont compatibles avec les hypoth√®ses du mod√®le lin√©aire (homosc√©dasticit√© et normalit√©). On passe maintenant √† l'analyse des sortie de mod√®le.
*** Intervalle de Confiance 

```{r}
# R√©cup√©ration des coefficients estim√©s
coefficients <- summary(modAnova)$coefficients[, 1]

# Calcul de l'intervalle de confiance des coefficients
IC_transformed <- confint(modAnova, level = 0.95)
print(IC_transformed)

# Si vous voulez revenir √† l'√©chelle originale, on applique la transformation inverse :
IC_original <- ((modAnova_pT$lambda * IC_transformed) + 1)^(1 /modAnova_pT$lambda)
print(IC_original)
```

 ***Visualisation graphique de ce r√©sultats 
```{r}
x <- barplot(1/sqrt(summary(modAnova)$coefficients[,1]),las=2)
arrows(x0 = x, y0= tabConfInt[,1],
  y1=tabConfInt[,2], code=3,angle=90,
  length=0.05)
```
# Coefficient de d√©termination 
```{r}
summary(modAnova)$r.squared
```
# Coefficient de d√©termination ajiust√© : 
```{r}
summary(modAnova)$adj.r.squared
```
Interpr√©tation : 

Le coefficient de d√©termination mesure la proportion de la variance expliqu√©e par le mod√®le par rapport √† la variance totale 5 c'est la somme de co√ªt quadratique. R2 = 0.876 signifie que 87,6 % de la variabilit√© totale des donn√©es est expliqu√©e par le mod√®le ANOVA. Cela indique un mod√®le qui s'ajuste bien aux donn√©es.
 # Visualisation Graphique : 
```{r}
barplot(c(
    sum((modAnova$residuals^2)),
    sum(modAnova$residuals^2)),
  col=c(4,2),
  names.arg=c("sans relev√©","avec relev√©"),ylab="Co√ªt quadratique")
```

# V√©rification √† l'aide d'un summary pour avoir une id√©e sur la valeur de P-Value et les resultats de Test de Fisher 
```{r}
summary(modAnova)
```
***R√©sultats de Test de Fisher 

Value : 207.726 (Statistique de Fisher)
numdf : 8 (Degr√©s de libert√© au num√©rateur, li√©s aux groupes ou facteurs dans le mod√®le)
dendf : 234 (Degr√©s de libert√© au d√©nominateur, li√©s aux r√©sidus ou √† l'√©chantillon total)
*** Interpr√©taion 

ùêπ=207.726 : Cette valeur de F test est tr√®s √©lev√©e. Cela sugg√®re une forte variation expliqu√©e par les groupes(les r√©l√©v√©es) dans le mod√®le par rapport √† la variation non expliqu√©e (r√©siduelle). En effet, plus F est grand, plus il est probable que les diff√©rences observ√©es entre les groupes soient significatives.
En mettent comme Hypoth√®ses test√©es :
 H0 : Les moyennes des diff√©rents groupes sont √©gales ( pas de variation interclasses)
 H1 : Au moins une des moyennes diff√®re des autres c√†d on a une variation interclasses ( propablement on a un effet de r√©l√©v√©e)
 
Le r√©sultas donn√©e par rapport au P-value < 0.05 confirme les r√©sultats donn√©es par le test de Fisher donc on rejette l'hy√¥th√®se H0 .
 
 




